---
title: 'Minería de datos: PEC3 - Clasificación con árboles de decisión'
author: "Autor: Gloria Manresa"
date: "Mayo 2023"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
    includes:
      in_header: 75.584-PEC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

```{r,warning = FALSE, message = FALSE}
# Importar librerías
library(ggplot2)
library(grid)
library(gridExtra)
library(arules)
library(dplyr)
library(DescTools)
library(C50)
library(randomForest)
library(iml)
```



# Carga de los datos e introducción

El conjunto de datos que se utilizará proviene de la página web de "UCI Machine Learning Repository". Recopilado originalmente por el Profesor Dr. Hans Hofmann.

Este conjunto de datos informa si un solicitante de crédito es "bueno" o "malo" en función de varias características. Contiene información sobre 1.000 solicitantes de crédito y un total de 20 atributos. 

La variable objetivo indica si el solicitante de crédito es considerado un buen riesgo crediticio (etiqueta "1") o un mal riesgo crediticio (etiqueta "2").

```{r message= FALSE, warning=FALSE}
data<-read.csv("./credit.csv",header=T,sep=",")
attach(data)
```

# Análisis inicial

Empezaremos realizando un análisis exploratorio de los datos para conocer más sobre el conjunto de datos con el que trabajaremos a continuación.

## Exploración de la base de datos

En primer lugar exploramos la dimensión del conjunto de datos, es decir el número de registros y el número de atributos. También exploraremos el tipo de atributo y descripción de cada uno de ellos.

Observamos a continuación que tenemos 1000 registros y 21 variables.

```{r}
dim(data)
```
A continuación, con la función str() conocemos el tipo de variable y observamos las primeros registros de cada una de ellas.

```{r}
str(data)
```
Una pequeña descripción de cada uno de los atributos:

- checking_balance: Estado de la cuenta corriente existente
- months_loan_duration: Duración del préstamo (en meses)
- credit_history: Historial de crédito
- purpose: Propósito del crédito
- amount: Cantidad del crédito
- savings_balance: Cuenta de ahorros
- employment_length: Duración del empleo actual
- installment_rate: Tasa de cuota en porcentaje del ingreso disponible
- personal_status: Estado civil y sexo
- other_debtors: Otros deudores / aval
- residence_history: Duración residencia actual
- property: Propiedad
- age: Edad
- installment_plan: Otros planes de cuotas
- housing: Vivienda (alquilada, propia, gratis)
- existing_credits: Número de créditos existentes en este banco
- dependents: Número de personas a su cargo
- telephone: Presencia de teléfono (sí o no)
- foreign_worker: Trabajador extranjero (sí o no)
- job: Trabajo (desempleado, no cualificado, cualificado, autónomo)

La variable objetivo es *"default"*. Este conjunto de datos clasifica a las personas descritas por un conjunto de atributos como buenos o malos riesgos crediticios. La variable "default" toma el valor 1 para "bueno" o 2 para "malo". Es decir, si una persona presenta "default" = 1 es probable que le acepten el crédito por presentar menos riesgo.

Vemos que las variables categóricas están definidas como "character", así que las transformamos a tipo factor.

```{r}
data$credit_history <- factor(data$credit_history)
data$checking_balance <- factor(data$checking_balance)
data$purpose <- factor(data$purpose)
data$savings_balance <- factor(data$savings_balance,
                               levels = c("< 100 DM","101 - 500 DM","501 - 1000 DM", "> 1000 DM","unknown"),
                               labels = c("<100","101-500","501-1000",">1000","unknown"))
data$employment_length <- factor(data$employment_length,
                               levels = c("unemployed","0 - 1 yrs","1 - 4 yrs","4 - 7 yrs", "> 7 yrs"),
                               labels = c("unemployed","0-1yrs","1-4yrs","4-7yrs", ">7yrs"))
data$personal_status <- factor(data$personal_status)
data$other_debtors <- factor(data$other_debtors,
                               levels = c("co-applicant","none","guarantor"))
data$property <- factor(data$property)
data$installment_plan <- factor(data$installment_plan)
data$housing <- factor(data$housing)
data$telephone <- factor(data$telephone)
data$foreign_worker <- factor(data$foreign_worker)
data$job <- factor(data$job)
```

También hay algunas variables definidas como "integer" que o bien son categóricas o bien se pueden tratar como tal por tener pocos valores únicos.

```{r}
data$installment_rate <- factor(data$installment_rate)
data$residence_history <- factor(data$residence_history)
data$existing_credits <- factor(data$existing_credits)
data$default <- as.factor(ifelse(data$default > 1, "Malo", "Bueno"))
data$dependents <- factor(data$dependents)
```

Todavía tenemos tres variables continuas tipo intenger. A continuación vamos a discretizar dichas variables.

## Discretizar variables continuas

A continuación vamos a discretizar la variable "months_loan_duration" para obtener intervalos. Dejamos que el algoritmo elija el conjunto de particiones.

```{r,warning = FALSE, message = FALSE}
set.seed(111)
table(discretize(data$months_loan_duration, "cluster" ))
```
Observamos que el algoritmo ha decidido 3 clústeres. A continuación los visualizamos.

```{r}
set.seed(111)
hist(data$months_loan_duration, main="Duración del préstamo (en meses)",xlab="Meses", ylab="Cantidad de préstamos",col = "ivory")
abline(v=discretize(data$months_loan_duration, method="cluster", onlycuts=TRUE),col="red")
```

Guardamos los intervalos en una nueva variable.

```{r}
set.seed(111)
data$months_loan_duration_disc <- discretize(data$months_loan_duration, "cluster" )
```


También vamos a discretizar la variable "amount" para obtener intervalos. Dejamos que el algoritmo elija el conjunto de particiones.

```{r,warning = FALSE, message = FALSE}
set.seed(111)
table(discretize(data$amount, "cluster" ))
```
Observamos que el algoritmo ha decidido 3 clústeres. A continuación los visualizamos.

```{r}
set.seed(111)
hist(data$amount, main="Cantidad del préstamo",xlab="Cantidad del préstamo", ylab="Cantidad de préstamos",col = "ivory")
abline(v=discretize(data$amount, method="cluster", onlycuts=TRUE),col="red")
```

Guardamos los intervalos en una nueva variable.

```{r}
set.seed(111)
data$amount_disc <- discretize(data$amount, "cluster" )
```


Por último, discretizamos la variable "age" para obtener intervalos. Dejamos que el algoritmo elija el conjunto de particiones.

```{r,warning = FALSE, message = FALSE}
set.seed(111)
table(discretize(data$age, "cluster" ))
```
Observamos que el algoritmo ha decidido 3 clústeres. A continuación los visualizamos.

```{r}
set.seed(111)
hist(data$age, main="Edad",xlab="Edad", ylab="Cantidad de préstamos",col = "ivory")
abline(v=discretize(data$age, method="cluster", onlycuts=TRUE),col="red")
```

Guardamos los intervalos en una nueva variable.

```{r}
set.seed(111)
data$age_disc <- discretize(data$age, "cluster" )
```

## Valores nulos
Continuamos explorando los datos, a continuación vamos a buscar cuantos valores nulos tenemos por columna.

```{r}
colSums(is.na(data))
```
Observamos que el conjunto de datos no presenta ningún valor nulo. Pero hemos visto que hay algunos valores que toman el valor de "unknown" vamos a ver cuantos tenemos.

```{r}
sapply(data, function(x) sum(x == "unknown"))
```
Observamos que tenemos valores "unknown" tanto en checking_balance como en savings_balance. De momento, los dejamos pero lo tendremos en cuenta en el próximo estudio.

## Visualización

A continuación vamos a visualizar las diferentes variables en función de la variable objetivo para conocer más acerca del conjunto de datos.

***

Checking balance

***

En el siguiente gráfico observamos como el riesgo disminuye cuanto mayor es la cantidad en la cuenta corriente. Una de las categorias es "desconocido" por lo que habrá que tenerlo en cuenta en la realización del árbol de decisión.

```{r}
plot(table(checking_balance, data$default)[c("< 0 DM","1 - 200 DM","> 200 DM","unknown"),], 
     col = c("#008000","red"), 
     main = "", 
     xlab = "Checking Balance", 
     ylab = "Credit risk")
```

***

Months loan duration

***

En el siguiente gráfico observamos como el riesgo aumenta en función de los meses del prestamo. Es decir, cuantos más meses abarca el préstamo mayor es el riesgo de impago.

```{r}
plot(table(data$months_loan_duration_disc,data$default), col = c("#008000","red"),
     main = "", 
     xlab = "Months loan duration", 
     ylab = "Credit risk")
```

***

Credit history

***

La información del siguiente gráfica puede parecer contradictoria ya que proporcionalmente indica más riesgo en los registros "fully repaid" que los valores "critical" y "delayed".

```{r}
df <- data %>%
  count(credit_history, default) %>%
  group_by(credit_history) %>%
  mutate(freq = n / sum(n)) %>%
  ungroup()

ggplot(data = df, aes(x = credit_history, fill = as.factor(default), y = freq, )) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(x = "Credit History", y = "Frequency") +  
  scale_fill_manual(values = c("#008000", "#e60047")) +  
  coord_flip()+
  guides(fill = guide_legend(title = "Credit risk"))
```

A continuación observamos que hay muy pocos registros "fully repaid" por lo que parece que proporcionalmente tienen bastantes registros de riesgo.

```{r}
ggplot(data, aes(x = credit_history)) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Credit History", y = "Frequency") +coord_flip()

```

***

Purpose

***

El propósito del crédito observamos que es variado y que en todos ellos existen registros con riesgo y sin.

```{r}
ggplot(data,aes(purpose))+geom_bar(aes(fill = default)) +labs(x="Purpose", y="Number of people")+ guides(fill=guide_legend(title="Credit risk"))+ scale_fill_manual(values=c("#008000","red"))+  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

***

Amount

***

Observamos a continuación que según aumenta el crédito también aumenta el riesgo. 

```{r}
df <- data %>%
  count(amount_disc, default) %>%
  group_by(amount_disc) %>%
  mutate(freq = n / sum(n)) %>%
  ungroup()

ggplot(data = df, aes(x = amount_disc, fill = as.factor(default), y = freq, )) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(x = "Credit amount", y = "Frequency") +  
  scale_fill_manual(values = c("#008000", "#e60047")) +  
  coord_flip()+
  guides(fill = guide_legend(title = "Credit risk"))
```

***

Savings balance

***

El riesgo disminuye a medida que aumentan los ahorros de dicha persona.

```{r}
plot(table(data$savings_balance,data$default), col = c("#008000","red"),main="Savings Balance", ylab = "Credit risk")
```

***

Employment length

***

El riesgo disminuye en función de los años de empleo, hasta llegar a los 7 años, donde parece que aumenta el riesgo ligeramente.

```{r}
plot(table(data$employment_length,data$default), col = c("#008000","red"), main = "Employment length", ylab ="Credit risk")
```

***

Installment rate

***

El riesgo aumenta muy ligeramente en función de la tasa de cuota en porcentaje del ingreso disponible.

```{r}
plot(table(installment_rate,data$default), col = c("#008000","red"), main = "Installment rate", ylab = "Credit risk")
```

***

Personal status

***

El estado civil parece tener poca influencia en el riesgo crediticio.

```{r}
plot(table(personal_status,data$default), col = c("#008000","red"), main = "Personal status", ylab = "Credit risk", xlab = "")
```

***

Other debtors

***

Observamos que la gran mayoría de créditos no presentan ni "co-applicant" ni "guarantor". También se observa que los créditos con "guarantor" persentan menos riesgo que el resto.

```{r}
plot(table(data$other_debtors,data$default), col = c("#008000","red"), main = "Other debtors", ylab = "Credit risk", xlab = "")
```

***

Residence history

***

El tiempo que lleva en la residencia actual no parece tener relación con el riesgo.

```{r}
plot(table(residence_history,data$default), col = c("#008000","red"), main = "Residence history", ylab = "Credit risk", xlab = "")
```


***

Property

***

 El riesgo disminuye en los propietarios de "real estate".

```{r}
plot(table(property,data$default), col = c("#008000","red"), main = "Property", ylab = "Credit risk", xlab = "")
```

***

Age

***

A continuación observamos como la edad se dividide en dos grandes grupos en relación al riesgo crediticio. Menores de 32 años existe más riesgo, y mayores de 32 años, menos riesgo.

```{r}
plot(table(data$age_disc,data$default), col = c("#008000","red"), main = "Age", ylab = "Credit risk", xlab = "")
```


***

Installment plan

***

El gráfico anterior muestra que las personas que no presentan ningún plan de pago a plazos, presentan menos riesgo que los que si que tienen.

```{r}
plot(table(installment_plan,data$default), col = c("#008000","red"), main = "Installment plan", ylab = "Credit risk", xlab = "")
```

***

Housing

***

Los propietarios de su propia vivienda presentan algo menos de riesgo que las personas que viven de alquiler o que las personas que viven gratuitamente en su vivienda.

```{r}
plot(table(housing,data$default), col = c("#008000","red"), main = "Housing", ylab = "Credit risk", xlab = "")
```

***

Existing Credits

***

En la gráfica anterior observamos que las personas que tienen 2 y 3 créditos presentan menos riesgo que las que tienen solo 1 y también que las que tienen 4.

Observamos que el número de muestras de 4 créditos es notablemente inferior al resto de muestras por lo que este conjunto podría estar sesgado.

```{r}
plot(table(existing_credits,data$default), col = c("#008000","red"), main = "Existing Credits", ylab = "Credit risk", xlab = "")
```

***

Dependents

***

No se observan diferencias de riesgo en lo que se refiere al número de personas a cargo por parte de la persona solicitante del crédito.

```{r}
plot(table(dependents,data$default), col = c("#008000","red"), main = "Dependents", ylab = "Credit risk", xlab = "")
```

***

Telephone

***

No se observan diferencias de riesgo en lo que se refiere a la posesión de un teléfono.

```{r}
plot(table(telephone,data$default), col = c("#008000","red"), main = "Telephone", ylab = "Credit risk", xlab = "")
```

***

Foreign worker

***

Observamos que el trabajador extranjero presenta bastante más riesgo que el que no lo es. También comentar que la muestra de trabajador extranjero es mucho más grande que la otra.

```{r}
plot(table(foreign_worker,data$default), col = c("#008000","red"), main = "Foreign worker", ylab = "Credit risk", xlab = "")
```

***

Job

***

Con respecto al trabajo no se observan diferencias significativas. Podríamos decir que el trabajador autónomo es el que presenta más riesgo, seguido de las personas desempleadas

```{r}
df <- data %>%
  count(job, default) %>%
  group_by(job) %>%
  mutate(freq = n / sum(n)) %>%
  ungroup()

ggplot(data = df, aes(x = job, fill = as.factor(default), y = freq, )) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(x = "Job", y = "Frequency") +  
  scale_fill_manual(values = c("#008000", "#e60047")) +  
  coord_flip()+
  guides(fill = guide_legend(title = "Credit risk"))
```

Observamos que la muestra de desempleados es muy pequeña en relación al resto.

```{r}
ggplot(data, aes(x = job)) +
  geom_bar() +
  theme_minimal() +
  labs(x = "Job", y = "Frequency") +coord_flip()
```

## Análisis de correlaciones

A continuación vamos a estudiar la relación que existen entre las variables categórigas respecto a la variable objetivo "default". Puesto que vamos a estudiar la asociación para tablas de contingencia de 2x2 utilizaremos el coeficiente de correlación phi.


```{r}
Phi(table(checking_balance,default))
Phi(table(data$months_loan_duration_disc,default))
Phi(table(credit_history,default))
Phi(table(purpose,default))
Phi(table(data$amount_disc,default))
Phi(table(savings_balance,default))
Phi(table(employment_length,default))
Phi(table(installment_rate,default))
Phi(table(personal_status,default))
Phi(table(other_debtors,default))
Phi(table(residence_history,default))
Phi(table(property,default))
Phi(table(data$age_disc,default))
Phi(table(installment_plan,default))
Phi(table(housing,default))
Phi(table(existing_credits,default))
Phi(table(dependents,default))
Phi(table(telephone,default))
Phi(table(foreign_worker,default))
Phi(table(job,default))
```

Teniendo en cuenta que la interpretación de este coeficiente podría ser:

- entre 0.1 y 0.3: asociación estadística es baja
- entre 0.3 y 0.5: asociación estadística media
- superior a 0.5: asociación estadística alta

Para la creación de arboles de decisión tendremos en cuenta estos parámetros para no utilizar las variables que presentan una asociación estadística demasiado baja con la variable objetivo.


# Creación de modelos

## Primer árbol de decisión

Para el primer árbol de decisión, no tendremos en cuenta la variable "checking_balance" ya que tenía un porcentaje muy alto de valores "unknown". Consideramos que se podría tratar como un valor NULO por lo que probaremos a realizar un árbol sin contar esta variable.

Las variables escogidas para este árbol serán las variables que tenían un coeficiente mayor a 0.15. Por otro lado eliminaremos los registros en los que "savings_balance" es "unknown".

```{r}
list1 = c("months_loan_duration","credit_history","purpose","amount","savings_balance","employment_length","property","age","installment_plan","housing","default")
data1 <- data[list1]
data1 <- subset(data1, savings_balance != "unknown")
```

A continuación separamos la variable objetivo (y) de las variables predictoras.

```{r}
set.seed(666)
y <- data1[,11] 
X <- data1[,1:10]
```

También dividimos el conjunto de datos para entrenar el modelo y para hacer el test. La proporción que utilizaremos será 2/3 para el conjunto de entrenamiento y 1/3 para el conjunto de prueba.

```{r}
split_prop <- 3 
indexes = sample(1:nrow(data1), size=floor(((split_prop-1)/split_prop)*nrow(data1)))
trainX<-X[indexes,]
trainy<-y[indexes]
testX<-X[-indexes,]
testy<-y[-indexes]
```

Realizamos un breve análisis de datos para asegurarnos que los subconjuntos presentan valores mezclados, no sesgados. 

```{r}
summary(trainX)
summary(trainy)
summary(testX)
summary(testy)
```

Una vez comprobado que no existen diferencias graves que puedan sesgar los resultados continuamos con el modelo.

A continuación creamos el árbol de decisión con los datos de entrenamiento.

```{r}
trainy <-  as.factor(trainy)
model1 <- C50::C5.0(trainX, trainy,rules=TRUE )
summary(model1)
```

Observamos que el porcentaje de error en este caso es de 25.4%. Es decir, de 544 registros, 138 se clasifican incorrectamente.

Las principales reglas de decisión son las siguientes:

- Regla 1: Si la duración del préstamo es menor o igual a 42 meses, el historial crediticio es crítico, demorado o pagado, y el monto del préstamo es menor o igual a 7814, entonces la clase asignada es "Bueno" con una confianza del 75.9%.
- Regla 2: Si la duración del préstamo es mayor a 42 meses, entonces la clase asignada es "Malo" (existe riesgo) con una confianza del 76.9%.
- Regla 3: Si la duración del préstamo es menor o igual a 42 meses y el monto del préstamo es mayor a 7814, entonces la clase asignada es "Malo" (existe riesgo) con una confianza del 70.4%.
- Regla 4: Si el historial crediticio es completamente pagado o completamente pagado en este banco, entonces la clase asignada es "Malo" (existe riesgo) con una confianza del 61.8%.

El árbol obtenido de este primer modelo es el siguiente:

```{r}
model1 <- C50::C5.0(trainX, trainy)
plot(model1,gp = gpar(fontsize = 9.5))
```

Observamos que aparentemente, la división de "credit_history" no parece tener demasiado sentido. Recordamos que, en el apartado de visualización, había etiquetas con muy pocos registros lo que puede llevar a sesgar los resultados.

Con este modelo, vamos a tratar de predecir la variable objetivo con el subconjunto de datos que habíamos reservado para ello.

```{r}
predicted_model1 <- predict( model1, testX, type="class" )
precision1 <- sum(predicted_model1 == testy) / length(predicted_model1)
print(sprintf("La precisión del árbol es: %.4f ",precision1))
```

La matriz de confusión es la siguiente, 

```{r}
mat_conf<-table(testy,Predicted=predicted_model1)
mat_conf
```
En la matriz de confusión observamos que 16 falsos positivos y 62 falsos negativos. 

El error de tipo 2 (falsos negativos) es el que deberíamos evitar en este caso, es decir, existe riesgo pero el modelo ha predicho que no lo hay. En este caso este error es más alto que el tipo 1.

```{r}
sensibilidad1 <- (168)/(168+62)
print(sprintf("La sensibilidad del modelo es: %.4f",sensibilidad1))
```

```{r}
F1 <- 2*((precision1*sensibilidad1)/(precision1+sensibilidad1))
print(sprintf("El F-measure del modelo 1 es: %.4f %%",F1))
```

### Variación del primer árbol de decisión

En este nuevo árbol vamos a continuar con la perspectiva del árbol anterior pero sin tener en cuenta la variable "credit_history" por lo mencionado anteriormente que una de las categorías presentan muy pocos registros y una de las reglas parece no tener sentido. Lo comprobaremos observando como funciona el modelo sin esta variable.

```{r}
list1.1 = c("months_loan_duration","purpose","amount","savings_balance","employment_length","property","age","installment_plan","housing","default")
data1.1 <- data[list1.1]
data1.1 <- subset(data1.1, savings_balance != "unknown")
```

A continuación separamos la variable objetivo (y) de las variables predictoras.

```{r}
set.seed(666)
y1.1 <- data1.1[,10] 
X1.1 <- data1.1[,1:09]
```

También dividimos el conjunto de datos para entrenar el modelo y para hacer el test. La proporción que utilizaremos será 2/3 para el conjunto de entrenamiento y 1/3 para el conjunto de prueba.

```{r}
split_prop <- 3 
indexes1.1 = sample(1:nrow(data1.1), size=floor(((split_prop-1)/split_prop)*nrow(data1.1)))
trainX1.1<-X1.1[indexes1.1,]
trainy1.1<-y1.1[indexes1.1]
testX1.1<-X1.1[-indexes1.1,]
testy1.1<-y1.1[-indexes1.1]
```

Realizamos un breve análisis de datos para asegurarnos que los subconjuntos presentan valores mezclados, no sesgados. 

```{r}
summary(trainX1.1)
summary(trainy1.1)
summary(testX1.1)
summary(testy1.1)
```

Una vez comprobado que no existen diferencias graves que puedan sesgar los resultados continuamos con el modelo.

A continuación creamos el árbol de decisión con los datos de entrenamiento.

```{r}
trainy1.1 <-  as.factor(trainy)
model1.1 <- C50::C5.0(trainX1.1, trainy1.1,rules=TRUE )
summary(model1.1)
```

Observamos que el porcentaje de error en este caso es de 20.2%. Ha mejorado respecto al árbol anterior.

Observamos que el árbol es bastante más grande y menos práctico e intuitivo.

El árbol obtenido de este primer modelo es el siguiente:

```{r}
model1.1 <- C50::C5.0(trainX1.1, trainy1.1)
plot(model1.1,gp = gpar(fontsize = 9.5))
```


Con este modelo, vamos a tratar de predecir la variable objetivo con el subconjunto de datos que habíamos reservado para ello.

```{r}
predicted_model1.1 <- predict( model1.1, testX1.1, type="class" )
precision1.1 <- sum(predicted_model1.1 == testy1.1) / length(predicted_model1.1)
print(sprintf("La precisión del árbol es: %.4f",precision1.1))
```
Observamos que la precisión ha disminuido ligeramente.

Vamos a ver si hemos mejorado en la tasa de "Falsos negativos". La matriz de confusión es la siguiente, 

```{r}
mat_conf1.1<-table(testy1.1,Predicted=predicted_model1.1)
mat_conf1.1
```
```{r}
sensibilidad1.1 <- (155)/(155+55)
print(sprintf("La sensibilidad del modelo es: %.4f",sensibilidad1.1))
```
La sensibilidad ha mejorado muy ligeramente.

```{r}
F1.1 <- 2*((precision1.1*sensibilidad1.1)/(precision1.1+sensibilidad1.1))
print(sprintf("El F-measure del modelo 1.1 es: %.4f",F1.1))
```
El F-measure no ha mejorado con respecto al anterior árbol. La mejora de la sensibilidad es demasiado pequeña para la complejidad de este árbol con respecto al enterior.

Vamos a continuar explorando para obtener un árbol con menos falsos negativos y mejor F-measure.

## Segundo árbol de decisión

En el siguiente árbol tendremos en cuenta la variable "checking_balance" pero borraremos los registros que toman valores "unknown". Tomaremos las variables que tenían un coeficiente mayor a 0.15. También se eliminaran los registros en los que "savings_balance" es "unknown".

Se ha decidido no utilizar "credit_history" en este árbol para evitar el sesgo que podría darse por las pocas muestras encontradas en algunas de sus etiquetas.

```{r}
list2 = c("checking_balance","months_loan_duration","purpose","amount","savings_balance","employment_length","property","age","installment_plan","housing","default")
data2 <- data[list2]
data2 <- subset(data2, savings_balance != "unknown")
data2 <- subset(data2, checking_balance != "unknown")
```

De nuevo, separamos la variable objetivo (y) de las variables predictoras.
```{r}
set.seed(666)
y2 <- data2[,11] 
X2 <- data2[,1:10]
```

Y dividimos el conjunto de datos para entrenar el modelo y para hacer el test.

```{r}
split_prop <- 3 
indexes2 = sample(1:nrow(data2), size=floor(((split_prop-1)/split_prop)*nrow(data2)))
trainX2<-X2[indexes2,]
trainy2<-y2[indexes2]
testX2<-X2[-indexes2,]
testy2<-y2[-indexes2]
```

Realizamos un breve análisis de datos para asegurarnos que los subconjuntos presentan valores mezclados, no sesgados.

```{r}
summary(trainX2)
summary(trainy2)
summary(testX2)
summary(testy2)
```

Una vez comprobado que no existen diferencias graves que puedan sesgar los resultados continuamos con el modelo.

A continuación creamos el árbol de decisión con los datos de entrenamiento.

```{r}
trainy2 <-  as.factor(trainy2)
model2 <- C50::C5.0(trainX2, trainy2,rules=TRUE )
summary(model2)
```
Observamos que el porcentaje de error en este caso es de 22.7%. Es decir, de 348 registros, 79 se clasifican incorrectamente. En este sentido se ha observado una ligera mejora respecto al anterior. También hay que tener en cuenta que este árbol es bastante más grande que el anterior, existen 11 reglas que pueden ser demasiadas para entender intuitivamente.

A continuación se explican las cuatro reglas principales de este árbol:

- Regla 1: Si el saldo de la cuenta corriente es mayor a 200 DM y la duración del préstamo es mayor a 30 meses, entonces se asigna la clase "Bueno" con una confianza del 83.3%.
- Regla 2: Si la duración del préstamo es menor o igual a 30 meses, entonces se asigna la clase "Bueno" con una confianza del 62.9%. Esta regla indica que, en general, para préstamos con una duración más corta, es más probable que la clase sea "Bueno".
- Regla 3: Si la duración del préstamo está entre 22 y 30 meses, el propósito del préstamo es un automóvil nuevo, el saldo de ahorros es inferior a 100 y se cumple la condición adicional de empleo, entonces se asigna la clase "Malo" con una confianza del 91.7%.
- Regla 4: Si el propósito del préstamo es un automóvil nuevo, el tiempo de empleo está en el rango de 0 a 1 año o es mayor a 7 años, y la vivienda es de alquiler, entonces se asigna la clase "Malo" con una confianza del 90%. Esta regla muestra que para los préstamos destinados a automóviles nuevos con ciertos periodos de empleo y viviendas de alquiler, es más probable que la clase sea "Malo".

A continuación se observa el árbol obetenido, que según comentado, es desmasiado grande y resulta poco práctico.
```{r}
model2 <- C50::C5.0(trainX2, trainy2)
plot(model2,gp = gpar(fontsize = 8))
```

A continuación se observa como la precisión del modelo ha empeorado considerablemente con respecto al anterior.

```{r}
predicted_model2 <- predict( model2, testX2, type="class" )
precision2 <- sum(predicted_model2 == testy2) / length(predicted_model2)
print(sprintf("La precisión del árbol es: %.4f", precision2))
```

```{r}
mat_conf2<-table(testy2,Predicted=predicted_model2)
mat_conf2
```

```{r}
sensibilidad2 <- (65)/(65+38)
print(sprintf("La sensibilidad del modelo es: %.4f",sensibilidad2))
```
La sensibilidad también ha empeorado por lo que el F-score, calculado a continuación, también empeorará con respecto a los modelos anteriores.

```{r}
F2 <- 2*((precision2*sensibilidad2)/(precision2+sensibilidad2))
print(sprintf("El F-measure del modelo 2 es: %.4f",F2))
```
Este modelo presenta una tasa de falsos negativos demasiado alta que haría perder demasiado dinero al prestamista.


## Tercer árbol de decisión con variación del paquete C5.0

A continuación, se exploran las variaciones del paquete C5.0 para generar árboles de decisión. Además, se introduce el "adaptative boosting", una técnica que utiliza múltiples clasificadores con sus respectivos árboles de decisión y reglas. Los clasificadores emiten votos y se suman para determinar la clase final asignada a un caso. El objetivo es comparar los resultados obtenidos y analizar cómo se modifica el árbol y su capacidad predictiva en el conjunto de prueba.

Puesto que por el momento el primer modelo ha sido el árbol de decisión con F-measure mayor los subconjuntos de datos que se utilizarán a continuación serán los mismos que se han utilizado en el primer árbol.

```{r}
modelo3 <- C50::C5.0(trainX, trainy, trials = 10)
plot(modelo3,gp = gpar(fontsize = 9.5))
```

```{r}
predicted_model3 <- predict( modelo3, testX, type="class" )
precision3 <- sum(predicted_model3 == testy) / length(predicted_model3)
print(sprintf("La precisión del árbol es: %.4f ",precision3))
```
Observamos que la precisión ha mejorado con respecto al árbol 1 realizado anteriormente.

```{r}
mat_conf3<-table(testy,Predicted=predicted_model3)
mat_conf3
sensibilidad3 <- (169)/(169+58)
print(sprintf("La sensibilidad del modelo es: %.4f",sensibilidad3))
```
La sensibilidad también ha mejorado, encontrando en este caso menos falsos negativos.

```{r}
F3 <- 2*((precision3*sensibilidad3)/(precision3+sensibilidad3))
print(sprintf("El F-measure del modelo 3 es: %.4f",F3))
```
Por último observamos que el F-measure también ha mejorado en este caso, aumentando de 0.7223 a 0.7385.

Vamos a estudiar la importancia de las variables en este modelo.

```{r}
importancia_usage <- C50::C5imp(modelo3, metric = "usage")
importancia_splits <- C50::C5imp(modelo3, metric = "splits")
importancia_usage
importancia_splits
```

De una manera más visual observamos a continuación la importancia de las variables en función de la frecuencia con la que se utilizan en los árboles generados.

```{r}
# USAGE- Convertir los valores de importancia en un dataframe
usage_df <- data.frame(Variables = rownames(importancia_usage),
                             Importancia = importancia_usage[,1])

# Crear el gráfico de barras con ggplot
ggplot(usage_df, aes(x = Importancia, y = reorder(Variables, Importancia))) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Importancia de las variables (usage)",
       x = "Importancia", y = "Variables") +
  theme_minimal()
```

Y en el siguiente gráfico observamos la importancia de las variables en función del número de divisiones que se realizan utilizando cada variable en los árboles generados.

```{r}
# SPLITS - Convertir los valores de importancia en un dataframe
splits_df <- data.frame(Variables = rownames(importancia_splits),
                             Importancia = importancia_splits[,1])

# Crear el gráfico de barras con ggplot
ggplot(splits_df, aes(x = Importancia, y = reorder(Variables, Importancia))) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Importancia de las variables (splits)",
       x = "Importancia", y = "Variables") +
  theme_minimal()
```


## Cuarto árbol de decisión con Random forest

Vamos a crear un conjunto de árboles de decisión con Random Forest y observaremos si podemos mejorar el modelo anterior.

```{r}
train.data <- as.data.frame(cbind(trainX,trainy))
colnames(train.data)[11] <- "DEFAULT"
rf <-  randomForest(DEFAULT ~ ., data = train.data, ntree = 50)
```

A continuación podemos visualizar la importancia de las variables. Este gráfico muestra la importancia relativa de cada variable en el modelo generado por randomForest.

```{r}
X4 <- train.data[which(names(train.data) != "DEFAULT")]
predictor <- Predictor$new(rf, data = X4, y = train.data$DEFAULT) 
imp <- FeatureImp$new(predictor, loss = "ce")
plot(imp)
```

```{r}
predicted_model4 <- predict( rf, testX, type="class" )
precision4 <- sum(predicted_model4 == testy) / length(predicted_model4)
print(sprintf("La precisión del árbol es: %.4f",precision4))
```

```{r}
mat_conf4<-table(testy, predicted_model4)
mat_conf4
```
```{r}
sensibilidad4 <- (160)/(160+59)
print(sprintf("La sensibilidad del modelo es: %.4f",sensibilidad4))
```

```{r}
F4 <- 2*((precision4*sensibilidad4)/(precision4+sensibilidad4))
print(sprintf("El F-measure del modelo de Random Forest es: %.4f",F4))
```
Observamos que este modelo no consigue mejorar el modelo creado anteriormente, presenta menor precisión, sensibilidad y por lo tanto F-measure.


# Conclusiones

En primer lugar realizamos una tabla con los árboles creados y sus métricas.

```{r}
# Crear los datos para el dataframe
nombre_modelo <- c("Primer árbol", "Variación primer árbol", "Segundo árbol", "Tercer árbol (Variación del paquete C5.0)", "Random forest")
precision <- c(precision1, precision1.1, precision2, precision3, precision4)
sensibilidad <- c(sensibilidad1, sensibilidad1.1, sensibilidad2,sensibilidad3,sensibilidad4)
fscore <- c(F1, F1.1, F2, F3, F4)

# Crear el dataframe
dataframe <- data.frame(
  "Precisión" = precision,
  "Sensibilidad" = sensibilidad,
  "F-score" = fscore
)

# Establecer los nombres de las filas
rownames(dataframe) <- nombre_modelo

# Mostrar el dataframe
print(dataframe)
```

El modelo que ha dado mejores resultados es el tercer árbol de decisión que se ha realizado utilizando el algoritmo C5.0 implementado en el paquete C50 en R e indicando trials = 10, lo que significa que se generarán 10 árboles y se seleccionará el mejor.

Este modelo ha obtenido el F-measure más alto (0.738), obteniendo también los valores de precisión (0.732) y sensibilidad (0.744) más altos que el resto de modelos generados.

Cabe mencionar que el árbol generado es sencillo por lo que es práctico e intuitivo.

```{r}
plot(modelo3,gp = gpar(fontsize = 9.5))
```

A pesar de haber obtenido las mejores métricas con este modelo se cree conveniente intentar ampliar el conjunto de datos para que las etiquetas de la variable "credit_history" tengan un número similar de registros cada una.